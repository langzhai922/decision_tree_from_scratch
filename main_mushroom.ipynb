{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading/Cleaning/Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclean_df = pd.read_csv('agaricus-lepiota.data')\n",
    "names = pd.read_csv('agaricus-lepiota.data')\n",
    "unclean_df.columns = ['edible?',\n",
    "              'capshape',\n",
    "              'cap-surface',\n",
    "              'cap-color',\n",
    "              'bruises?',\n",
    "              'odor',\n",
    "              'gill-attachment',\n",
    "              'gill-spacing',\n",
    "              'gill-size',\n",
    "              'gill-color',\n",
    "              'stalk-shape',\n",
    "              'stalk-root',\n",
    "              'stalk-surface-above-ring',\n",
    "              'stalk-surface-below-ring',\n",
    "              'stalk-color-above-ring',\n",
    "              'stalk-color-below-ring',\n",
    "              'veil-type',\n",
    "              'veil-color',\n",
    "              'ring-number',\n",
    "              'ring-type',\n",
    "              'spore-print-color',\n",
    "              'population',\n",
    "              'habitat'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p']\n"
     ]
    }
   ],
   "source": [
    "# looking at the raw data, we can see that variable 16 is all classified the same\n",
    "test = unclean_df['veil-type'].unique()\n",
    "print(test)\n",
    "# We can remove this column as it is not useful for prediction.\n",
    "unclean_df2 = unclean_df.drop('veil-type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove missing data\n",
    "df = unclean_df2.loc[(unclean_df2['stalk-root'] != '?')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 3781, length of test dataset: 1862\n"
     ]
    }
   ],
   "source": [
    "# split data into train and test set\n",
    "def test_train_split(df, test_proportion):\n",
    "\n",
    "    if isinstance(test_proportion, float):\n",
    "        test_proportion = round(test_proportion * len(df))\n",
    "    \n",
    "    rows = df.index.tolist()\n",
    "    test_rows = random.sample(population=rows, k=test_proportion)\n",
    "    test_set = df.loc[test_rows]\n",
    "    train_set = df.drop(test_rows)\n",
    "    \n",
    "    return train_set, test_set\n",
    "\n",
    "# get train and test set\n",
    "# use different proportions to test for different models\n",
    "random.seed(2)\n",
    "train_df, test_df = test_train_split(df, 0.33)\n",
    "print(\"Length of train dataset: {}, length of test dataset: {}\".format(len(train_df), len(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn dataframe into array for other functions to use\n",
    "# numpy array more efficient than dataframe\n",
    "train_data = train_df.values\n",
    "test_data = test_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Training Procedure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if at a node, all mushrooms are the same (perfectly classified)\n",
    "def check_mushroom_edibility(data):\n",
    "    y_vals = data[:,0]\n",
    "    unique_classes = np.unique(y_vals)\n",
    "    if len(unique_classes) != 2:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all possible ways to test the data\n",
    "def get_possible_splits(data):\n",
    "    splits = {}\n",
    "    _, n_col = data.shape\n",
    "    \n",
    "    for col_index in range(n_col):\n",
    "        vals = data[:, col_index]\n",
    "        unique_val = np.unique(vals)\n",
    "        splits[col_index] = unique_val\n",
    "\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate expected entropy of a variable\n",
    "def calculate_entropy(data, split_col_index, split_vals_list):\n",
    "    entropy_list = []\n",
    "    count_list = []\n",
    "    for value in split_vals_list:\n",
    "        attribute_data = data[(data[:,split_col_index]) == value]\n",
    "        _, counts = np.unique(attribute_data[:,0], return_counts=True)\n",
    "        probs = counts / counts.sum()\n",
    "        entropy = sum(-probs * np.log2(probs))\n",
    "        entropy_list.append(entropy)\n",
    "        count_list.append(len(attribute_data))\n",
    "    expected_entropy = 0\n",
    "    for i in range(len(entropy_list)):\n",
    "        expected_entropy += entropy_list[i] * count_list[i] / len(data)\n",
    "    return expected_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best possible split\n",
    "def find_best_split(data, possible_splits, headers):\n",
    "    # loop over all variables\n",
    "    entropy_list = []\n",
    "    for i in range(1,len(possible_splits)):\n",
    "        entropy = calculate_entropy(data, i, possible_splits[i])\n",
    "        entropy_list.append(entropy)\n",
    "    index = np.array(entropy_list).argmin()\n",
    "    best_split = headers[index+1]\n",
    "    return best_split, index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine if the leaf node is predominantly edible or poisonous.\n",
    "def classifier(data):\n",
    "    labels = data[:,0]\n",
    "    edibility, indices = np.unique(labels, return_counts=True)\n",
    "    index = indices.argmax()\n",
    "    classification = edibility[index]\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisiontreealgorithm(data, stopping_depth, counter=0, headers=0):\n",
    "    # keep track of headers for entropy calculation\n",
    "    if counter == 0:\n",
    "        headers = train_df.columns\n",
    "\n",
    "    # base case\n",
    "    if counter == stopping_depth or check_mushroom_edibility(data):\n",
    "        label = classifier(data)\n",
    "        return label\n",
    "    \n",
    "    # inductive step\n",
    "    else:\n",
    "        counter += 1\n",
    "        # find highest information gain variable to split on\n",
    "        possible_splits = get_possible_splits(data)\n",
    "        best_split, index = find_best_split(data, possible_splits, headers)\n",
    "        headers = np.delete(headers, index)\n",
    "\n",
    "        # build tree\n",
    "        tree = {}\n",
    "        attribute_list = possible_splits[index]\n",
    "\n",
    "        # interate through all attributes, appending new subtree each time\n",
    "        for attribute in attribute_list:\n",
    "            details = \"Split feature {}, on class: {}\".format(best_split, attribute)\n",
    "            old_attribute_data = data[data[:,index] == attribute]\n",
    "            # remove variable which is now useless for prediction\n",
    "            attribute_data = np.delete(old_attribute_data, index, axis=1)\n",
    "            subtree = decisiontreealgorithm(attribute_data, stopping_depth, counter, headers)\n",
    "            tree[details] = [subtree]\n",
    "\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Split feature odor, on attribute: a': ['e'],\n",
       " 'Split feature odor, on attribute: c': ['p'],\n",
       " 'Split feature odor, on attribute: f': ['p'],\n",
       " 'Split feature odor, on attribute: l': ['e'],\n",
       " 'Split feature odor, on attribute: m': ['p'],\n",
       " 'Split feature odor, on attribute: n': [{'Split feature spore-print-color, on attribute: k': ['e'],\n",
       "   'Split feature spore-print-color, on attribute: n': ['e'],\n",
       "   'Split feature spore-print-color, on attribute: r': ['p'],\n",
       "   'Split feature spore-print-color, on attribute: w': ['e']}],\n",
       " 'Split feature odor, on attribute: p': ['p']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decisiontreealgorithm(train_data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Split feature odor, on attribute: a': ['e'],\n",
       " 'Split feature odor, on attribute: c': ['p'],\n",
       " 'Split feature odor, on attribute: f': ['p'],\n",
       " 'Split feature odor, on attribute: l': ['e'],\n",
       " 'Split feature odor, on attribute: m': ['p'],\n",
       " 'Split feature odor, on attribute: n': [{'Split feature spore-print-color, on attribute: k': ['e'],\n",
       "   'Split feature spore-print-color, on attribute: n': ['e'],\n",
       "   'Split feature spore-print-color, on attribute: r': ['p'],\n",
       "   'Split feature spore-print-color, on attribute: w': [{'Split feature cap-color, on attribute: c': ['e'],\n",
       "     'Split feature cap-color, on attribute: g': ['e'],\n",
       "     'Split feature cap-color, on attribute: n': ['e'],\n",
       "     'Split feature cap-color, on attribute: p': ['e'],\n",
       "     'Split feature cap-color, on attribute: w': ['p'],\n",
       "     'Split feature cap-color, on attribute: y': ['p']}]}],\n",
       " 'Split feature odor, on attribute: p': ['p']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decisiontreealgorithm(train_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Split feature odor, on attribute: a': ['e'],\n",
       " 'Split feature odor, on attribute: c': ['p'],\n",
       " 'Split feature odor, on attribute: f': ['p'],\n",
       " 'Split feature odor, on attribute: l': ['e'],\n",
       " 'Split feature odor, on attribute: m': ['p'],\n",
       " 'Split feature odor, on attribute: n': [{'Split feature spore-print-color, on attribute: k': ['e'],\n",
       "   'Split feature spore-print-color, on attribute: n': ['e'],\n",
       "   'Split feature spore-print-color, on attribute: r': ['p'],\n",
       "   'Split feature spore-print-color, on attribute: w': [{'Split feature cap-color, on attribute: c': ['e'],\n",
       "     'Split feature cap-color, on attribute: g': ['e'],\n",
       "     'Split feature cap-color, on attribute: n': ['e'],\n",
       "     'Split feature cap-color, on attribute: p': ['e'],\n",
       "     'Split feature cap-color, on attribute: w': ['p'],\n",
       "     'Split feature cap-color, on attribute: y': ['p']}]}],\n",
       " 'Split feature odor, on attribute: p': ['p']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decisiontreealgorithm(train_data, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification step\n",
    "# Pass in our instance and our trained model, output the label (edible = e, poisonous = p)\n",
    "def classify(instance, model):\n",
    "    already_classified = [[\"e\"], [\"p\"]]\n",
    "    # remove outer list when variable splits\n",
    "    if isinstance(model, dict):\n",
    "        split_det = list(model.keys())[0]\n",
    "        feature_index = split_det.find(\",\")\n",
    "    else:\n",
    "        [unpack_model] = model\n",
    "        split_det = list(unpack_model.keys())[0]\n",
    "        feature_index = split_det.find(\",\")\n",
    "        model = unpack_model\n",
    "        \n",
    "    # extract root feature and split value\n",
    "    model_feature = str(split_det)[14:feature_index]\n",
    "    model_answer = str(split_det)[-1:]\n",
    "\n",
    "    # base case\n",
    "    if str(instance[model_feature]) == model_answer:\n",
    "        if model[split_det] in already_classified:\n",
    "            return model[split_det]\n",
    "        return classify(instance, model[split_det])\n",
    "\n",
    "    # inductive step\n",
    "    # if instance feature does not match with model, delete model question and iterate through again\n",
    "    else:\n",
    "        dummy_model = model.copy()\n",
    "        dummy_model.pop(split_det)\n",
    "        return classify(instance, dummy_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify test set\n",
    "def accuracy_testing(df, model):\n",
    "    incorrect = 0\n",
    "    incorrect_indices = []\n",
    "    for index, inst in df.iterrows():\n",
    "        label = classify(inst, model)\n",
    "        if label[0] != inst[0]:\n",
    "            incorrect += 1\n",
    "            incorrect_indices.append(index)\n",
    "    incorrect_df = df[df.index.isin(incorrect_indices)]\n",
    "    return incorrect, incorrect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edible?</th>\n",
       "      <th>odor</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>cap-color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7599</th>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>w</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7738</th>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>w</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5127</th>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7482</th>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>w</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     edible? odor spore-print-color cap-color\n",
       "7599       p    n                 w         y\n",
       "7738       p    n                 w         y\n",
       "5127       p    n                 w         w\n",
       "5280       p    n                 w         w\n",
       "7482       p    n                 w         y"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the model\n",
    "model = decisiontreealgorithm(test_data, 2)\n",
    "incorrect_no, incorrect_df = accuracy_testing(test_df, model)\n",
    "incorrect_df[[\"edible?\",\"odor\",\"spore-print-color\",\"cap-color\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000223998618225391"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_error - test_error = approximate_error\n",
    "model = decisiontreealgorithm(test_data, 2)\n",
    "test_no, _ = accuracy_testing(test_df, model)\n",
    "train_no, _ = accuracy_testing(train_df, model)\n",
    "train_no / len(train_df) - test_no / len(test_df)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2440bff9db2479c55237947f096727da8e2301dc725da8608080e99b92f074ff"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('361GroupProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
